## 维基HTML代码存档（Py-crawler）

这是用来创建一个爬虫工程，用于爬取wiki上存在的所有页面，用于在受灾后的网站静态只读版本。可能不适用于恢复工程，但是为恢复页面提供了依据。

### **配置要求和依赖项**
```
Python3，
使用爬虫需要安装bs4库和requests库！
```

请使用以下代码安装：
```
pip install requests
pip install bs4
```

注意！python3安装时需要选择“添加python到PATH”才能用pip命令

运行时启用RunMe.vbs(GUI)或main.exe(CLI)

Linux用户自行编译。

生成的a.html可以删除

---------

Copyright (c) 2022 TimeLine-Bookstore  
All Rights Reserved.
